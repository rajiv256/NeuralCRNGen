{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff32dbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg;\n",
    "Pkg.add(\"ReactionNetworkImporters\");\n",
    "Pkg.add(\"Dictionaries\");\n",
    "Pkg.add(\"LaTeXStrings\");\n",
    "Pkg.add(\"Statistics\");\n",
    "Pkg.add(\"ColorSchemes\");\n",
    "Pkg.add(\"IterTools\"); \n",
    "Pkg.add(\"NNlib\"); \n",
    "Pkg.add(\"DifferentialEquations\");\n",
    "# Pkg.add(\"Plots\");\n",
    "Pkg.add(\"Formatting\");\n",
    "Pkg.add(\"LinearAlgebra\");\n",
    "Pkg.add(\"Noise\");\n",
    "Pkg.add(\"Catalyst\");\n",
    "\n",
    "using DifferentialEquations;\n",
    "using Random;\n",
    "# using Plots;\n",
    "using Formatting;\n",
    "using LinearAlgebra;\n",
    "using Noise;\n",
    "using ReactionNetworkImporters;\n",
    "using Dictionaries;\n",
    "using LaTeXStrings;\n",
    "using Statistics;\n",
    "using ColorSchemes;\n",
    "using Catalyst;\n",
    "using IterTools;\n",
    "using NNlib;\n",
    "\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93235185",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"datasets.jl\")\n",
    "include(\"utils.jl\")\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad1dab94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward_step (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f(u, p, x, t)\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        u: hidden state\n",
    "        params: [length(z)**2 + 2*length(z)]\n",
    "    \"\"\"\n",
    "    theta, beta, w, h, _, _ = sequester_params(p)\n",
    "    hvec = ones(length(w))*h\n",
    "    \n",
    "    fmat = (theta*x + beta).*u - u.*u + hvec \n",
    "    @assert length(fmat) == length(x)\n",
    "    return fmat\n",
    "end\n",
    "\n",
    "\n",
    "function forward!(du, u, xAndp, t)\n",
    "    \"\"\"\n",
    "    xAndp: [x, theta, beta, w, h, t0, t1]\n",
    "    \"\"\"\n",
    "    x = xAndp[1:length(u)]\n",
    "    p = xAndp[length(u)+1:end]\n",
    "    \n",
    "    func = f(u, p, x, t)\n",
    "    \n",
    "    for i in eachindex(func)\n",
    "        du[i] = func[i]\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "# Calculates the final hidden state of the neural ode\n",
    "function forward_node(u0, xAndp, tspan)\n",
    "    \n",
    "    prob = ODEProblem(forward!, u0, tspan, xAndp)\n",
    "    sol = solve(prob, Tsit5(), reltol=1e-8, abstol=1e-8)\n",
    "    return sol\n",
    "end\n",
    "\n",
    "\n",
    "# Final feedforward layer similar to a perceptron\n",
    "function forward_ffnet(z, w; threshold=nothing)\n",
    "    yhat = dot(w, z) # Verified!\n",
    "    # CHECK: Thinking of the final layer as a binary perceptron \n",
    "    # println(\"ODE | yhat at t=T: $yhat\")\n",
    "    \n",
    "    return yhat\n",
    "end\n",
    "\n",
    "\n",
    "function forward_step(u0, p, tspan; threshold=nothing)\n",
    "    \n",
    "    xAndp = []\n",
    "    append!(xAndp, u0)\n",
    "    append!(xAndp, p)\n",
    "    \n",
    "    theta, beta, w, h, t0, t1 = sequester_params(p, dims=length(u0))\n",
    "    # Output from the neural ode\n",
    "    node_out = forward_node(u0, xAndp, tspan)\n",
    "    # Extracting hidden state\n",
    "    z = node_out.u[end][1:length(u0)]\n",
    "    \n",
    "    yhat = forward_ffnet(z, w, threshold=threshold)\n",
    "    return (z, yhat)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f393ad8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backpropagation_step (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function aug_dynamics!(du, u, sAndp, t)\n",
    "    \n",
    "    s0 = sAndp[1:3]\n",
    "    p = sAndp[4:end]\n",
    "    theta, beta, w, h, _, _ = sequester_params(p)\n",
    "    dims = Int32(sqrt(length(theta)))\n",
    "\n",
    "    # Time dynamics for the hidden state\n",
    "    offset = 0\n",
    "    z = u[1:dims]\n",
    "    func = -f(u, p, z, t)\n",
    "\n",
    "    @assert length(func) == dims\n",
    "\n",
    "    for i in 1:dims\n",
    "        du[offset+i] = func[i]\n",
    "    end\n",
    "\n",
    "#     offset += dims\n",
    "\n",
    "\n",
    "#     # Time dynamics for the adjoint\n",
    "#     a = u[dims+1:2*dims]\n",
    "#     a = reshape(a, (dims, 1))\n",
    "\n",
    "#     # ‚àÇf/‚àÇz = ùúÉ\n",
    "#     dfdz = theta\n",
    "#     @assert size(theta) == (dims, dims)\n",
    "\n",
    "#     dadt = reshape(-transpose(a) * dfdz, dims)\n",
    "#     for i in eachindex(dadt)\n",
    "#         du[offset+i] = dadt[i]\n",
    "#     end\n",
    "\n",
    "#     offset += length(dadt)\n",
    "#     @assert offset == 2 * dims # offset after adding dzdt and dady\n",
    "\n",
    "\n",
    "#     # Time dynamics for gradients\n",
    "#     dfdtheta = zeros(dims, dims^2)\n",
    "\n",
    "#     for i in 1:dims\n",
    "#         for j in 1:dims\n",
    "#             dfdtheta[i, (i-1)*dims+j] = z[j]\n",
    "#         end\n",
    "#     end\n",
    "\n",
    "#     dgrads = -transpose(a) * dfdtheta\n",
    "\n",
    "#     @assert size(dgrads) == (1, dims^2)\n",
    "\n",
    "#     for i in eachindex(dgrads)\n",
    "#         du[offset+i] = dgrads[i]\n",
    "#     end\n",
    "#     offset += length(dgrads)\n",
    "\n",
    "#     # Time dynamics of time(!!): Not used though sigh.\n",
    "#     # TODO: Might wanna change this in future if things don't work\n",
    "#     dfdt = zeros(dims, 1)\n",
    "#     tgrads = -transpose(a) * dfdt\n",
    "\n",
    "#     @assert length(tgrads) == 1\n",
    "\n",
    "#     # currently not changing time!\n",
    "#     du[offset+1] = 0\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function backpropagation_step(s0, p, tspan; dims=3)\n",
    "    theta, beta, w, h, _, _ = sequester_params(p, dims=dims)\n",
    "    \n",
    "    sAndp = []\n",
    "    append!(sAndp, s0)\n",
    "    append!(sAndp, p)\n",
    "    println(\"sAndp: \", s0, p)\n",
    "    prob = ODEProblem(aug_dynamics!, s0, tspan, sAndp)\n",
    "    sol = solve(prob, Tsit5(), reltol=1e-8, abstol=1e-8)\n",
    "    return sol\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17c082ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node_main (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function training_step(x, y, p; threshold=nothing)\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: augmented input\n",
    "        y: output \n",
    "        p: parameters of the entire network\n",
    "    \"\"\"\n",
    "    dims = length(x)\n",
    "    \n",
    "    theta, beta, w, h, t0, t1 = sequester_params(p, dims=dims)\n",
    "    tspan = (t0, t1)\n",
    "    \n",
    "    @assert length(w) == dims \n",
    "    \n",
    "    # Forward & Hidden state calculation\n",
    "    println(\"ODE | w at t=0 | \", w)\n",
    "    \n",
    "    z, yhat = forward_step(x, p, tspan, threshold=threshold)\n",
    "    z = reshape(z, (dims, 1)) # Make z a row-vector\n",
    "    \n",
    "    println(\"ODE | z at t=T | \", z)\n",
    "    # Loss\n",
    "    loss = 0.5*(yhat-y)^2\n",
    "    \n",
    "#     # Adjoint calculation\n",
    "#     a = (yhat-y)*w\n",
    "#     a = reshape(a, (dims, 1))\n",
    "#     println(\"ODE | yhat at t=T | \", yhat)\n",
    "#     println(\"ODE | Adjoint at t=T | \", a)\n",
    "    \n",
    "#     # Initial theta gradients\n",
    "#     gtheta = zeros(dims^2, 1)\n",
    "#     println(\"ODE | Theta gradients at t=T | \", gtheta)\n",
    "    \n",
    "#     # Initial time gradients \n",
    "#     func = f(z, theta, beta, x)\n",
    "\n",
    "#     dldt1 = -transpose(a)*f(z, theta, beta, x)\n",
    "#     dldt1 = convert(Array{Float64}, dldt1)\n",
    "    \n",
    "    # Initial state for the reverse time ODE\n",
    "#     s0 = vcat(z, a, gtheta, dldt1)\n",
    "    s0 = z # Just for check\n",
    "    \n",
    "#     rtspan = reverse(tspan)\n",
    "    backward = backpropagation_step(s0, p, tspan)\n",
    "    println(\"ODE | z at t=0 | \", backward.u[end][1:dims])\n",
    "    gradients = nothing\n",
    "#     println(\"ODE | Adjoint at t=0 | \", backward.u[end][dims+1:2*dims])\n",
    "    \n",
    "#     gradients = backward.u[end][2*dims+1:end]\n",
    "#     gradients = reshape(gradients, size(gradients)[1])\n",
    "    \n",
    "#     # Note that gradients[end] already contains gradient for t0\n",
    "#     append!(gradients, dldt1) # gradient for t1\n",
    "    \n",
    "#     # Gradients wrt w\n",
    "#     wgrads = (yhat-y)*z\n",
    "#     println(\"ODE | error: \", yhat-y)\n",
    "#     # println(\"ODE | wgrads, z: \", wgrads, z)\n",
    "#     for i in eachindex(wgrads)\n",
    "#         push!(gradients, wgrads[i])\n",
    "#     end\n",
    "#     println(\"ODE | M: Final layer gradients | \", wgrads)\n",
    "#     println(\"ODE | G: Gradients at t=0 | \", gradients)\n",
    "    return z, yhat, loss, gradients\n",
    "end\n",
    "\n",
    "\n",
    "function one_step_node(x, y, params, LR, dims)\n",
    "    println(\"=======ODE==================\")\n",
    "    println(\"ODE | Input: $x | Target: $y\")\n",
    "    println(\"params before | \", params)\n",
    "    z, yhat, loss, gradients = training_step(x, y, params)\n",
    "\n",
    "    # Parameter update\n",
    "    for param_index in eachindex(gradients)\n",
    "        params[param_index] -= LR * gradients[param_index]\n",
    "    end\n",
    "    params[dims^2+1] = 0.0\n",
    "    params[dims^2+2] = 1.0\n",
    "    println(\"==============ODE END=============\")\n",
    "    return params\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "################################################################## \n",
    "\n",
    "function node_main(params, train, val; dims=3, EPOCHS=20, LR=0.001, threshold=nothing)\n",
    "    # Begin the training process\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    for epoch in 1:EPOCHS\n",
    "        epoch_loss = 0.0\n",
    "        for i in eachindex(train)\n",
    "            println(\"=========EPOCH: $epoch | ITERATION: $i ===========\")\n",
    "            x, y = get_one(train, i)\n",
    "            \n",
    "            # Augment\n",
    "            x = augment(x, dims-length(x))\n",
    "            for j in 1:length(x)\n",
    "                x[j] = abs(x[j])\n",
    "            end\n",
    "            println(\"ODE | Input: $x | Target: $y\")\n",
    "            theta, beta, w, h, t0, t1 = sequester_params(params)\n",
    "            println(\"Ideal ReLU | \", relu.(theta*x + beta))\n",
    "            println(\"params before | \", params)\n",
    "            z, yhat, loss, gradients = training_step(x, y, params, threshold=threshold)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "#             for param_index in eachindex(gradients)\n",
    "#                 params[param_index] -= LR * gradients[param_index]\n",
    "#             end\n",
    "#             params[dims^2+1] = 0.0\n",
    "#             params[dims^2+2] = 1.0\n",
    "#             println(\"params at t=0 after update | \", params)\n",
    "        end\n",
    "#         epoch_loss /= length(train)\n",
    "#         push!(losses, epoch_loss)\n",
    "#         lossplts = plot(losses)\n",
    "#         # png(lossplts, \"trainlossplts.png\")\n",
    "#         accuracy = 0.0\n",
    "#         val_epoch_loss = 0.0\n",
    "#         before = []\n",
    "#         after = []\n",
    "#         yhats = []\n",
    "#         for v in eachindex(val)\n",
    "#             println(\"=======VAL Epoch: $epoch | ITERATION: $v\")\n",
    "#             x, y = get_one(val, v)\n",
    "\n",
    "#             # Augment\n",
    "#             x = augment(x, dims - length(x))\n",
    "#             dims = length(x)\n",
    "\n",
    "#             theta, beta, w, t0, t1= sequester_params(params, dims)\n",
    "#             tspan = (t0, t1)\n",
    "#             @assert length(w) == dims\n",
    "\n",
    "#             # Forward & Hidden state calculation\n",
    "#             println(\"ODE | w at t=0 | \", w)\n",
    "\n",
    "#             before_tmp = []\n",
    "#             append!(before_tmp, x)\n",
    "#             push!(before_tmp, y)\n",
    "#             push!(before, before_tmp)\n",
    "\n",
    "#             println(\"ODE | Input: $x | Target: $y\")\n",
    "#             println(\"params before | \", params)\n",
    "#             z, yhat = forward_step(x, theta, w, tspan, threshold=threshold)\n",
    "#             loss = 0.5 * (yhat - y)^2\n",
    "        \n",
    "#             class = math.ceil(yhat)\n",
    "#             after_tmp = []\n",
    "#             append!(after_tmp, z)\n",
    "#             push!(after_tmp, y)\n",
    "#             push!(after, after_tmp)\n",
    "\n",
    "\n",
    "#             val_epoch_loss += loss\n",
    "#             println(\"params | \", params)\n",
    "\n",
    "#             yhats_tmp = []\n",
    "#             append!(yhats_tmp, x)\n",
    "#             push!(yhats_tmp, class)\n",
    "#             push!(yhats, yhats_tmp)\n",
    "\n",
    "#             if class == y\n",
    "#                 accuracy += 1\n",
    "#             end\n",
    "#         end\n",
    "        # if dims == 2\n",
    "            # beforeplt = scatter(getindex.(before, 1), getindex.(before, 2), group=getindex.(before, 3))\n",
    "            # afterplot = scatter(getindex.(after, 1), getindex.(after, 2), group=getindex.(after, 3))\n",
    "            # yhatplt = scatter(getindex.(yhats, 1), getindex.(yhats, 2), group=getindex.(yhats, 3))\n",
    "        # end\n",
    "        # if dims==3\n",
    "            # beforeplt = scatter3d(getindex.(before, 1), getindex.(before, 2), getindex.(before, 3), group=getindex.(before, 4))\n",
    "            # afterplot = scatter3d(getindex.(after, 1), getindex.(after, 2), getindex.(after, 3), group=getindex.(after, 4))\n",
    "            # yhatplt = scatter3d(getindex.(yhats, 1), getindex.(yhats, 2), getindex.(yhats, 3), group=getindex.(yhats, 4))\n",
    "        # end\n",
    "        # png(beforeplt, \"before.png\")\n",
    "        # png(afterplot, \"after.png\")\n",
    "#         println(\"accuracy: \", accuracy / length(val))\n",
    "        \n",
    "        \n",
    "        # png(yhatplt, \"yhats.png\")\n",
    "\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e15121ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========EPOCH: 1 | ITERATION: 1 ===========\n",
      "ODE | Input: [0.11241656541824341, 0.4358801543712616, 0.0] | Target: -1.0\n",
      "Ideal ReLU | [0.26884228960859996, 0.6384834862007127, 0.8997631288451635]\n",
      "params before | Any[0.8334208454, 0.0103126134, 1.8675020091, 0.1686510643, 0.9794816587, 1.5727820922, 0.0643065187, 0.2435356233, 0.8191115101, 0.1706569171, 0.1925876962, 0.7863816658, 0.4702697478, 0.2403057774, 1.1513489769, 0.1, 0.0, 4.0]\n",
      "ODE | w at t=0 | Any[0.4702697478, 0.2403057774, 1.1513489769]\n",
      "ODE | z at t=T | [0.43142417728770766; 0.7543119449420583; 0.8794857907479267;;]\n",
      "sAndp: [0.43142417728770766; 0.7543119449420583; 0.8794857907479267;;]Any[0.8334208454, 0.0103126134, 1.8675020091, 0.1686510643, 0.9794816587, 1.5727820922, 0.0643065187, 0.2435356233, 0.8191115101, 0.1706569171, 0.1925876962, 0.7863816658, 0.4702697478, 0.2403057774, 1.1513489769, 0.1, 0.0, 4.0]\n",
      "ODE | z at t=0 | [-0.21120420472677606, -0.159424385202493, -0.08508218892106033]\n"
     ]
    }
   ],
   "source": [
    " function neuralode(; DIMS=3)\n",
    "    # train = create_linearly_separable_dataset(100, linear, threshold=0.0)\n",
    "    # val = create_linearly_separable_dataset(40, linear, threshold=0.0)\n",
    "    train = create_annular_rings_dataset(150)\n",
    "    val = create_annular_rings_dataset(50)  \n",
    "    # val = train   \n",
    "\n",
    "    params_orig = create_node_params(DIMS, t0=0.0, t1=4.0)\n",
    "    for i in 1:length(params_orig)\n",
    "        params_orig[i] = abs(params_orig[i])\n",
    "    end\n",
    "    theta, beta, w, h, t0, t1 = sequester_params(params_orig)\n",
    "    node_main(params_orig, train[1:1], val[1:1], dims=DIMS, EPOCHS=1, threshold=0.0, LR=0.001)\n",
    "end\n",
    "\n",
    "neuralode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307351f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0cd7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fbc159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
